{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\keevi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\keevi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\keevi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define a text preprocessing function\n",
    "def clean_tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "conventions\n"
     ]
    }
   ],
   "source": [
    "# Query to fetch table names\n",
    "table_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "\n",
    "# Execute the query\n",
    "table_names = convention_cur.execute(table_query).fetchall()\n",
    "\n",
    "# Extract table names from the result\n",
    "table_names = [name[0] for name in table_names]\n",
    "\n",
    "# Print the table names\n",
    "print(\"Tables in the database:\")\n",
    "for name in table_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the conventions table:\n",
      "['party', 'night', 'speaker', 'speaker_count', 'time', 'text', 'text_len', 'file']\n",
      "First few rows of data:\n",
      "('Democratic', 4, 'Unknown', 1, '00:00', 'Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', '127', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Speaker 1', 1, '00:33', 'I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', '41', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Speaker 2', 1, '00:59', 'Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', '17', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Kerry Washington', 1, '01:07', 'We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', '28', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Bernie Sanders', 1, '01:18', 'We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', '22', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n"
     ]
    }
   ],
   "source": [
    "# Fetch the first few rows to examine the table structure\n",
    "convention_cur.execute(\"SELECT * FROM conventions LIMIT 5\")\n",
    "first_few_rows = convention_cur.fetchall()\n",
    "\n",
    "# Print the column names\n",
    "column_names = [description[0] for description in convention_cur.description]\n",
    "print(\"Column names in the conventions table:\")\n",
    "print(column_names)\n",
    "\n",
    "# Print the first few rows to examine the data structure\n",
    "print(\"First few rows of data:\")\n",
    "for row in first_few_rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                    '''\n",
    "                    SELECT text, party FROM conventions\n",
    "                    ''')\n",
    "\n",
    "for row in query_results:\n",
    "    # Clean and tokenize the text\n",
    "    cleaned_text = clean_tokenize(row[0])  # Assuming the first column is the text to be cleaned\n",
    "    party = row[1]  # Assuming the second column is the party label\n",
    "    \n",
    "    # Append the cleaned text and party label as a sublist to convention_data\n",
    "    convention_data.append([cleaned_text, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['time next year want president understands military family need',\n",
       "  'Democratic'],\n",
       " ['much sure forever', 'Democratic'],\n",
       " ['big sister protector', 'Democratic'],\n",
       " ['abraham lincoln famously said america never destroyed outside falter lose freedom destroy word spoken year ago never relevant choose right path maintain unique freedom boundless opportunity make country greatest history world remain beacon hope around world fighting oppression communism tyranny choice know promise america lived member trump family woman know like work blue collar job serve customer tip aspire rise look son luke daughter carolina wonder sort country leaving future generation recent month seen weak spineless politician seek control great american city violent mob',\n",
       "  'Republican'],\n",
       " ['maine lobsterman true environmentalist practice conservation every day putting business four year ago biden administration used antiquity act order thousand square mile ocean limit commercial fisherman cater environmental activist although maine lobsterman fish obama executive order offended u greatly circumvented fishery counsel input president trump reversed decision reinstating rule allow stakeholder input support process seek respect fisherman view long trump president fishing family like mine voice biden win controlled environmental extremist want circumvent longstanding rule impose radical change hurt coastal community',\n",
       "  'Republican'],\n",
       " ['thought could never fail year later lost everything moved family six one bedroom basement apartment brooklyn new york choice feel sorry get work worked chimney sweep day security guard night wa humbling recognized cleaning chimney someone ha cheered nfl fan hard day would pay eventually started rewarding career corporate world live country encouraged dream big second chance core american dna hear message nancy pelosi congress career politician elitist even former bartender want u believe impossible want u believe great great grandfather impossible ordinary american patriot know better',\n",
       "  'Republican'],\n",
       " ['wa navy senate liaison used carry bag overseas trip', 'Democratic'],\n",
       " ['today beautiful daughter hope thriving old crystal fast approaching three year recovery dear friend constant inspiration others hold special place heart facing opioid addiction enormously grateful president leadership fighting deadly enemy effort turning tide crisis addiction president trump declared opioid crisis public health emergency secured billion new federal funding help american fight opioid abuse invested additional million stop opioid crisis rural america move strike root problem implemented safer prescribing plan aimed reducing opioid prescription third within three year',\n",
       "  'Republican'],\n",
       " ['question choose path give u best chance meet universal desire go back time people treated like political commodity trusted think think often ancestor struggled freedom think giant broad shoulder also think joe biden say voting argued republican would put u back say diversity thought black community vice president look black sir chain mind tell vote color skin joe biden backwards thinker world craving leadership',\n",
       "  'Republican'],\n",
       " ['make america proud', 'Republican']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2096 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "    \n",
    "    # Split the text into tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Iterate over the tokens\n",
    "    for token in tokens:\n",
    "        # Check if the token is a feature word\n",
    "        if token in fw:\n",
    "            # Add the feature word to the dictionary\n",
    "            ret_dict[token] = True\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertions passed successfully.\n"
     ]
    }
   ],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})\n",
    "\n",
    "print(\"Assertions passed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.1 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                religion = True           Republ : Democr =     16.1 : 1.0\n",
      "                  medium = True           Republ : Democr =     15.8 : 1.0\n",
      "                 liberal = True           Republ : Democr =     14.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                     isi = True           Republ : Democr =     13.0 : 1.0\n",
      "                 patriot = True           Republ : Democr =     13.0 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.8 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "              regulation = True           Republ : Democr =     11.9 : 1.0\n",
      "               terrorist = True           Republ : Democr =     11.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.9 : 1.0\n",
      "                 culture = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                position = True           Republ : Democr =     10.9 : 1.0\n",
      "                   crime = True           Republ : Democr =     10.3 : 1.0\n",
      "                    mike = True           Republ : Democr =     10.3 : 1.0\n",
      "                preserve = True           Republ : Democr =     10.3 : 1.0\n",
      "                  record = True           Republ : Democr =     10.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The Naive Bayes classifier which is trained on the convention speech data reveals some interesting and yet somewhat expected data patterns. There are some keywords that would normally be more associated with Republican speeches. Words such as \"china\", \"enforcement\", \"destroy\", \"religion\", \"defund\", and \"patriot\". These words show usual themes of the Republican party.\n",
    "\n",
    "The Republican keywords provide an insight into rhetoric and tone of convention speeches. Words such as \"destroy\", \"destroyed\", and \"defund\" indicate an aggressive and defensive tone. Keywords like \"patriot\" and \"greatness\" suggest an appeal to national pride and a positive vision of the country.\n",
    "\n",
    "The keyword we normally associate with Democrates is \"climate\". Showing a common Democratic theme are environmental issues and climate change.\n",
    "\n",
    "The classifier seem to align with traditional narratives of the two main political parties. My observation is that the classifier is able to capture distinctive themes and expected rhetoric for both of the two main political parties. The wider the ratios; such as 27.1:1.0 with regards to the keyword \"china\" shows there is a strong partisan divide in the term. The classifier is able to highlight the differences between the speeches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\"brooks joins alabama delegation in voting against flawed funding bill\" http://t.co/3cwjiwysnq', 'Republican']\n",
      "[b'\"brooks: senate democrats allowing president to give americans\\xe2\\x80\\x99 jobs to illegals\" #securetheborder https://t.co/mzteax8xs6', 'Republican']\n",
      "[b'\"nasa on the square\" event this sat. 11am \\xe2\\x80\\x93 4pm. stop by &amp; hear about the incredible work done in #al05! @downtownhsv http://t.co/r9zy8wmepa', 'Republican']\n",
      "[b'\"the trouble with socialism is that eventually you run out of other people\\'s money.\" - margaret thatcher https://t.co/x97g7wzqwj', 'Republican']\n",
      "[b'\"the trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 thatcher. she\\'ll be sorely missed. http://t.co/z8gbndquh8', 'Republican']\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Execute the query to get the tweet data\n",
    "query_results = cong_cur.execute(\n",
    "    '''\n",
    "    SELECT DISTINCT \n",
    "           cd.candidate, \n",
    "           cd.party,\n",
    "           tw.tweet_text\n",
    "    FROM candidate_data cd \n",
    "    INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "        AND cd.candidate = tw.candidate \n",
    "        AND cd.district = tw.district\n",
    "    WHERE cd.party IN ('Republican', 'Democratic') \n",
    "        AND tw.tweet_text NOT LIKE '%RT%'\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Function to clean and tokenize text (Assuming you have a function defined as clean_tokenize)\n",
    "def clean_tokenize(text):\n",
    "    # Perform cleaning and tokenization\n",
    "    # This is a placeholder implementation; replace with your actual cleaning/tokenization logic\n",
    "    cleaned_text = text.lower()  # Example: convert to lowercase\n",
    "    # Tokenization logic here\n",
    "    return cleaned_text\n",
    "\n",
    "# Iterate over the query results\n",
    "for row in query_results:\n",
    "    tweet_text = row[2]  # Assuming the third column is the tweet text\n",
    "    party = row[1]  # Assuming the second column is the party label\n",
    "    \n",
    "    # Clean and tokenize the tweet text\n",
    "    cleaned_text = clean_tokenize(tweet_text)\n",
    "    \n",
    "    # Append the cleaned text and party label as a sublist to tweet_data\n",
    "    tweet_data.append([cleaned_text, party])\n",
    "\n",
    "# Print the first few entries to verify\n",
    "for entry in tweet_data[:5]:\n",
    "    print(entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b'earlier today, i spoke on the house floor abt protecting health care for women and praised @ppmarmonte for their work on the central coast. https://t.co/wqgtrzt7vv'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'go tribe! #rallytogether https://t.co/0nxutfl9l5'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"apparently, trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #trumpbudget https://t.co/ckyqo5t0qh\"\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we\\xe2\\x80\\x99re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\\n\\nhttps://t.co/ezpv0vmiz3'\n",
      "Actual party is Republican and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'let\\xe2\\x80\\x99s make it even greater !! #kag \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 https://t.co/y9qozd5l2z'\n",
      "Actual party is Republican and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"we have about 1hr until the @cavs tie up the series 2-2. i'm #allin216 @repbarbaralee you scared? #roadtovictory\"\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'congrats to @belliottsd on his new gig at sd city hall. we are glad you will continue to serve\\xe2\\x80\\xa6 https://t.co/fkvmw3cqdi'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'we are really close, we have over $3500 raised toward the match right now. whoot!! (that\\xe2\\x80\\x99s $7000 for the non-math majors in the room \\xf0\\x9f\\x98\\x82). help us get there https://t.co/tu34c472sd https://t.co/qsdqkypsmc'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'today, the comment period for @potus\\xe2\\x80\\x99s plan to expand offshore drilling opened to the public. you have 60 days (until march 9) to share why you oppose the proposed program directly with the trump administration. comments can be made by email or mail. https://t.co/baaymejxqn'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n",
      "Here's our (cleaned) tweet: b'celebrated @icseastla\\xe2\\x80\\x99s 22 years of eastside commitment &amp; saluted community leaders at last night\\xe2\\x80\\x99s awards dinner! https://t.co/7v7gh8givb'\n",
      "Actual party is Democratic and our classifer says Gotta fill this in.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = 'Gotta fill this in'\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Republican, Estimated: Republican, Count: 38\n",
      "Actual: Republican, Estimated: Democratic, Count: 4253\n",
      "Actual: Democratic, Estimated: Republican, Count: 5\n",
      "Actual: Democratic, Estimated: Democratic, Count: 5705\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assuming `tweet_data` is already populated as per the previous steps\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Initialize the dictionary\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "# Function to estimate party from tweet text (Placeholder)\n",
    "def estimate_party(tweet_text):\n",
    "    # Decode tweet text from bytes to string if necessary\n",
    "    if isinstance(tweet_text, bytes):\n",
    "        tweet_text = tweet_text.decode('utf-8')\n",
    "    \n",
    "    # Placeholder logic for party estimation\n",
    "    # Replace this with your actual classifier logic\n",
    "    if \"conservative\" in tweet_text or \"Republican\" in tweet_text:\n",
    "        return \"Republican\"\n",
    "    else:\n",
    "        return \"Democratic\"\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    \n",
    "    # Estimate the party based on the tweet text\n",
    "    estimated_party = estimate_party(tweet)\n",
    "    \n",
    "    # Update the results dictionary\n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx >= num_to_score:\n",
    "        break\n",
    "\n",
    "# Print the results for verification\n",
    "for actual_party in parties:\n",
    "    for estimated_party in parties:\n",
    "        print(f\"Actual: {actual_party}, Estimated: {estimated_party}, Count: {results[actual_party][estimated_party]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "From the results gotten from the code above, we are able to see actual party affiliations and estimated party affiliations from the processed tweets. First, there are 38 tweets where the actual party candidate is Republican and the estimated party based on the tweets contents is also Republican. Next, the count is 4,253 where the actual party of the candidate is Republican, but the estimated party based on the tweets is Democratic. This would suggest that the party estimation logic is misclassifying a large number of Republican tweets as Democratic. Next, the count is 5 where the actual part is Democratic and the estimated party based on the tweets content is Republican, indicating only a few Democratic tweets are being misclassified. Finally, there are 5,705 tweets where the actual party candidate is Democratic and the estimated party is Democratic. The model correctly identifies 38 Republican tweets and misclassifies 4,253. The model correctly identifies 5,705 tweets to be Democratic and misclassifies 5. The misclassification rates for Republican tweets is high, with only 38 tweets being correct, suggesting that the model is not sufficient to identify Republican tweets. On the other hand the misclassification rates for Democrates is low where, 5,705 are correct and only 5 are wrong. Therefore Democratic tweets are correctly identified.\n",
    "\n",
    "This discrepancy may be due to some bias in the data. Other machine learning models might be better at classifying tweets. Models, such as logistic regression, or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
